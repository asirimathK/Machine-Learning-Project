{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fe0235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns found: ['Company Names', 'Cars Names', 'Engines', 'Capacity', 'HorsePower', 'Total Speed', 'Performance', 'Cars Prices', 'Fuel Types', 'Seats', 'Torque']\n",
      "\n",
      "=== Test Performance ===\n",
      "R²:   0.8861\n",
      "MAE:  41,059\n",
      "RMSE: 239,209\n",
      "\n",
      "Top +/− features (log-price coefficients):\n",
      "       feature      coef\n",
      "       bugatti  2.843000\n",
      "   lamborghini  2.600290\n",
      "         volvo -2.466252\n",
      "    car petrol  1.608302\n",
      "           car  1.608302\n",
      "       ferrari  1.436593\n",
      "   volvo volvo -1.233126\n",
      "            gt  0.947224\n",
      "   nissan gt-r  0.859683\n",
      "       porsche  0.805548\n",
      "         super -0.802828\n",
      "     chevrolet -0.800730\n",
      "        3500hd -0.749410\n",
      "  nismo petrol -0.747744\n",
      "bugatti chiron  0.745090\n",
      "        chiron  0.745090\n",
      "         nismo  0.736684\n",
      "        martin  0.734739\n",
      "  aston martin  0.734739\n",
      "         aston  0.734739\n",
      "\n",
      "Baseline price (exp(intercept)): ~28,281\n"
     ]
    }
   ],
   "source": [
    "# --- Car Price Prediction using your columns ---\n",
    "# Text: Company Names, Cars Names, Fuel Types\n",
    "# Numeric: Capacity, Seats\n",
    "# Target: Cars Prices\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import unicodedata as ud\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# ========= 1) LOAD =========\n",
    "file_path = \"/Users/atheequehasan/Downloads/CSV/NewCopy15cleanCarsCopy1df_filtered.csv\"\n",
    "df = pd.read_csv(file_path, encoding=\"utf-8-sig\")  # BOM-safe\n",
    "\n",
    "# (Optional) normalize weird whitespace in column names\n",
    "def _clean_col(s: str) -> str:\n",
    "    s = ud.normalize(\"NFKC\", str(s))\n",
    "    s = s.replace(\"\\ufeff\", \"\").replace(\"\\u200b\", \"\").replace(\"\\u200c\", \"\").replace(\"\\u200d\", \"\")\n",
    "    return \" \".join(s.strip().split())\n",
    "df.columns = [_clean_col(c) for c in df.columns]\n",
    "\n",
    "print(\"Columns found:\", list(df.columns))\n",
    "\n",
    "\n",
    "# ========= 2) LOAD & NUMERIC TYPE PARSING =========\n",
    "\n",
    "df = pd.read_csv(file_path, encoding=\"utf-8-sig\", thousands=\",\")\n",
    "# enforce numeric (will raise if any stray text slipped through)\n",
    "df[\"Cars Prices\"] = pd.to_numeric(df[\"Cars Prices\"], errors=\"raise\")\n",
    "df[\"Capacity\"]    = pd.to_numeric(df[\"Capacity\"], errors=\"raise\")\n",
    "df[\"Seats\"]       = pd.to_numeric(df[\"Seats\"], errors=\"raise\")\n",
    "\n",
    "\n",
    "# Drop rows with missing target\n",
    "df = df.dropna(subset=[\"Cars Prices\"]).reset_index(drop=True)\n",
    "\n",
    "# ========= 3) FEATURES =========\n",
    "text_cols = [\"Company Names\", \"Cars Names\", \"Fuel Types\"]\n",
    "num_cols  = [\"Capacity\", \"Seats\"]\n",
    "target    = \"Cars Prices\"\n",
    "\n",
    "# Sanity check\n",
    "missing = set(text_cols + num_cols + [target]) - set(df.columns)\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing columns: {missing}\")\n",
    "\n",
    "# ========= 4) PIPELINE: TF-IDF (text) + NUMERIC =========\n",
    "def combine_text(X):\n",
    "    \"\"\"Combine the selected text columns into a single string per row.\"\"\"\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        return (X.astype(str).agg(\" \".join, axis=1)).to_numpy()\n",
    "    return (pd.DataFrame(X).astype(str).agg(\" \".join, axis=1)).to_numpy()\n",
    "\n",
    "text_pipe = Pipeline(steps=[\n",
    "    (\"combine\", FunctionTransformer(combine_text, validate=False)),\n",
    "    # Keep tokens like '1.5T', 'i-VTEC', 'G-Limited'\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        lowercase=True,\n",
    "        ngram_range=(1, 2),\n",
    "        min_df=3,\n",
    "        max_features=30000,\n",
    "        token_pattern=r\"(?u)\\b[\\w\\.-]+\\b\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "num_pipe = Pipeline(steps=[\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler(with_mean=False))  # plays nicely with sparse TF-IDF\n",
    "])\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    (\"text\", text_pipe, text_cols),\n",
    "    (\"num\",  num_pipe,  num_cols),\n",
    "])\n",
    "\n",
    "# Regularized linear model on log(price)\n",
    "reg = RidgeCV(alphas=np.logspace(-3, 3, 25))\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"pre\", pre),\n",
    "    (\"reg\", reg)\n",
    "])\n",
    "\n",
    "# ========= 5) TRAIN/TEST & FIT =========\n",
    "X = df[text_cols + num_cols]\n",
    "y = np.log1p(df[target])  # log target for stability\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ========= 6) EVALUATION (back on original price scale) =========\n",
    "y_pred_log = model.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "\n",
    "r2   = r2_score(np.expm1(y_test), y_pred)\n",
    "mae  = mean_absolute_error(np.expm1(y_test), y_pred)\n",
    "rmse = mean_squared_error(np.expm1(y_test), y_pred, squared=False)\n",
    "\n",
    "print(\"\\n=== Test Performance ===\")\n",
    "print(f\"R²:   {r2:.4f}\")\n",
    "print(f\"MAE:  {mae:,.0f}\")\n",
    "print(f\"RMSE: {rmse:,.0f}\")\n",
    "\n",
    "# ========= 7) FEATURE INSPECTION (robust to older sklearn) =========\n",
    "import numpy as np\n",
    "\n",
    "ct = model.named_steps[\"pre\"]           # ColumnTransformer\n",
    "reg = model.named_steps[\"reg\"]          # RidgeCV\n",
    "\n",
    "# Get text feature names from the inner TF-IDF vectorizer\n",
    "text_vect = ct.named_transformers_[\"text\"].named_steps[\"tfidf\"]\n",
    "text_features = text_vect.get_feature_names_out()\n",
    "\n",
    "# Numeric feature names are the original numeric columns\n",
    "num_features = np.array(num_cols, dtype=object)\n",
    "\n",
    "# Final feature name order in ColumnTransformer is [text, then num]\n",
    "feature_names = np.concatenate([text_features, num_features], axis=0)\n",
    "\n",
    "coefs = reg.coef_\n",
    "assert len(coefs) == len(feature_names), (\n",
    "    f\"Length mismatch: {len(coefs)} coefs vs {len(feature_names)} features\"\n",
    ")\n",
    "\n",
    "coef_df = (\n",
    "    pd.DataFrame({\"feature\": feature_names, \"coef\": coefs})\n",
    "      .assign(abs_coef=lambda d: d[\"coef\"].abs())\n",
    "      .sort_values(\"abs_coef\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"\\nTop +/− features (log-price coefficients):\")\n",
    "print(coef_df.head(20)[[\"feature\", \"coef\"]].to_string(index=False))\n",
    "\n",
    "base_price = float(np.exp(reg.intercept_))\n",
    "print(f\"\\nBaseline price (exp(intercept)): ~{base_price:,.0f}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
